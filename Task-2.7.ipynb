{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_7748\\4122061654.py:1: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(r\"C:\\Users\\admin\\OneDrive\\Desktop\\pharma project-6\\Pharma-project-6\\sales_data.zip\")\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(r\"C:\\Users\\admin\\OneDrive\\Desktop\\pharma project-6\\Pharma-project-6\\sales_data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(r\"C:\\Users\\admin\\OneDrive\\Desktop\\pharma project-6\\Pharma-project-6\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge test_df with store_df\n",
    "df = pd.merge(df1, df2, on=['Store', 'DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday'], how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017204</th>\n",
       "      <td>1017204</td>\n",
       "      <td>1111</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017205</th>\n",
       "      <td>1017205</td>\n",
       "      <td>1112</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017206</th>\n",
       "      <td>1017206</td>\n",
       "      <td>1113</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017207</th>\n",
       "      <td>1017207</td>\n",
       "      <td>1114</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017208</th>\n",
       "      <td>1017208</td>\n",
       "      <td>1115</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1017209 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Store  DayOfWeek        Date  Sales  Customers  Open  \\\n",
       "0                 0      1          5  2015-07-31   5263        555     1   \n",
       "1                 1      2          5  2015-07-31   6064        625     1   \n",
       "2                 2      3          5  2015-07-31   8314        821     1   \n",
       "3                 3      4          5  2015-07-31  13995       1498     1   \n",
       "4                 4      5          5  2015-07-31   4822        559     1   \n",
       "...             ...    ...        ...         ...    ...        ...   ...   \n",
       "1017204     1017204   1111          2  2013-01-01      0          0     0   \n",
       "1017205     1017205   1112          2  2013-01-01      0          0     0   \n",
       "1017206     1017206   1113          2  2013-01-01      0          0     0   \n",
       "1017207     1017207   1114          2  2013-01-01      0          0     0   \n",
       "1017208     1017208   1115          2  2013-01-01      0          0     0   \n",
       "\n",
       "         Promo StateHoliday  SchoolHoliday  Id  \n",
       "0            1            0              1 NaN  \n",
       "1            1            0              1 NaN  \n",
       "2            1            0              1 NaN  \n",
       "3            1            0              1 NaN  \n",
       "4            1            0              1 NaN  \n",
       "...        ...          ...            ...  ..  \n",
       "1017204      0            a              1 NaN  \n",
       "1017205      0            a              1 NaN  \n",
       "1017206      0            a              1 NaN  \n",
       "1017207      0            a              1 NaN  \n",
       "1017208      0            a              1 NaN  \n",
       "\n",
       "[1017209 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1017209, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1017209 entries, 0 to 1017208\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count    Dtype  \n",
      "---  ------         --------------    -----  \n",
      " 0   Unnamed: 0     1017209 non-null  int64  \n",
      " 1   Store          1017209 non-null  int64  \n",
      " 2   DayOfWeek      1017209 non-null  int64  \n",
      " 3   Date           1017209 non-null  object \n",
      " 4   Sales          1017209 non-null  int64  \n",
      " 5   Customers      1017209 non-null  int64  \n",
      " 6   Open           1017209 non-null  int64  \n",
      " 7   Promo          1017209 non-null  int64  \n",
      " 8   StateHoliday   1017209 non-null  object \n",
      " 9   SchoolHoliday  1017209 non-null  int64  \n",
      " 10  Id             0 non-null        float64\n",
      "dtypes: float64(1), int64(8), object(2)\n",
      "memory usage: 85.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>1.017209e+06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.086040e+05</td>\n",
       "      <td>5.584297e+02</td>\n",
       "      <td>3.998341e+00</td>\n",
       "      <td>5.773819e+03</td>\n",
       "      <td>6.331459e+02</td>\n",
       "      <td>8.301067e-01</td>\n",
       "      <td>3.815145e-01</td>\n",
       "      <td>1.786467e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.936431e+05</td>\n",
       "      <td>3.219087e+02</td>\n",
       "      <td>1.997391e+00</td>\n",
       "      <td>3.849926e+03</td>\n",
       "      <td>4.644117e+02</td>\n",
       "      <td>3.755392e-01</td>\n",
       "      <td>4.857586e-01</td>\n",
       "      <td>3.830564e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.543020e+05</td>\n",
       "      <td>2.800000e+02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.727000e+03</td>\n",
       "      <td>4.050000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.086040e+05</td>\n",
       "      <td>5.580000e+02</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>5.744000e+03</td>\n",
       "      <td>6.090000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.629060e+05</td>\n",
       "      <td>8.380000e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>7.856000e+03</td>\n",
       "      <td>8.370000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.017208e+06</td>\n",
       "      <td>1.115000e+03</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>4.155100e+04</td>\n",
       "      <td>7.388000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0         Store     DayOfWeek         Sales     Customers  \\\n",
       "count  1.017209e+06  1.017209e+06  1.017209e+06  1.017209e+06  1.017209e+06   \n",
       "mean   5.086040e+05  5.584297e+02  3.998341e+00  5.773819e+03  6.331459e+02   \n",
       "std    2.936431e+05  3.219087e+02  1.997391e+00  3.849926e+03  4.644117e+02   \n",
       "min    0.000000e+00  1.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    2.543020e+05  2.800000e+02  2.000000e+00  3.727000e+03  4.050000e+02   \n",
       "50%    5.086040e+05  5.580000e+02  4.000000e+00  5.744000e+03  6.090000e+02   \n",
       "75%    7.629060e+05  8.380000e+02  6.000000e+00  7.856000e+03  8.370000e+02   \n",
       "max    1.017208e+06  1.115000e+03  7.000000e+00  4.155100e+04  7.388000e+03   \n",
       "\n",
       "               Open         Promo  SchoolHoliday   Id  \n",
       "count  1.017209e+06  1.017209e+06   1.017209e+06  0.0  \n",
       "mean   8.301067e-01  3.815145e-01   1.786467e-01  NaN  \n",
       "std    3.755392e-01  4.857586e-01   3.830564e-01  NaN  \n",
       "min    0.000000e+00  0.000000e+00   0.000000e+00  NaN  \n",
       "25%    1.000000e+00  0.000000e+00   0.000000e+00  NaN  \n",
       "50%    1.000000e+00  0.000000e+00   0.000000e+00  NaN  \n",
       "75%    1.000000e+00  1.000000e+00   0.000000e+00  NaN  \n",
       "max    1.000000e+00  1.000000e+00   1.000000e+00  NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Store', 'DayOfWeek', 'Date', 'Sales', 'Customers',\n",
       "       'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'Id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0             0\n",
       "Store                  0\n",
       "DayOfWeek              0\n",
       "Date                   0\n",
       "Sales                  0\n",
       "Customers              0\n",
       "Open                   0\n",
       "Promo                  0\n",
       "StateHoliday           0\n",
       "SchoolHoliday          0\n",
       "Id               1017209\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Store  DayOfWeek        Date  Sales  Customers  Open  Promo  \\\n",
      "0           0      1          5  2015-07-31   5263        555     1      1   \n",
      "1           1      2          5  2015-07-31   6064        625     1      1   \n",
      "2           2      3          5  2015-07-31   8314        821     1      1   \n",
      "3           3      4          5  2015-07-31  13995       1498     1      1   \n",
      "4           4      5          5  2015-07-31   4822        559     1      1   \n",
      "\n",
      "   SchoolHoliday  Id  StateHoliday_encoded  \n",
      "0              1 NaN                     0  \n",
      "1              1 NaN                     0  \n",
      "2              1 NaN                     0  \n",
      "3              1 NaN                     0  \n",
      "4              1 NaN                     0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the data\n",
    "\n",
    "# Step 1: Convert any numeric values in 'StateHoliday' to strings\n",
    "df['StateHoliday'] = df['StateHoliday'].astype(str)\n",
    "\n",
    "# Step 2: Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Step 3: Fit and transform the 'StateHoliday' column\n",
    "df['StateHoliday_encoded'] = label_encoder.fit_transform(df['StateHoliday'])\n",
    "\n",
    "# Step 4: Convert the encoded column to integer type\n",
    "df['StateHoliday_encoded'] = df['StateHoliday_encoded'].astype(int)\n",
    "\n",
    "# Step 5: Optionally, you may drop the original 'StateHoliday' column\n",
    "df.drop(columns=['StateHoliday'], inplace=True)\n",
    "\n",
    "# Display the DataFrame to confirm the changes\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df.drop(columns=['Unnamed: 0', 'Id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_7748\\2099656834.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_7748\\2099656834.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_7748\\2099656834.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_7748\\2099656834.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define columns with missing values\n",
    "numeric_cols = ['Sales', 'Customers']\n",
    "categorical_cols = ['Store', 'DayOfWeek', 'Promo', 'SchoolHoliday']\n",
    "\n",
    "# Impute missing values for numeric columns\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Fill missing values for categorical columns with mode\n",
    "for col in categorical_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering with Dates\n",
    "# Convert 'Date' from object to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Extract year, month, day from 'Date'\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "\n",
    "# Optionally, you can also extract other components like day of week and whether it's the end of the month, etc.\n",
    "# Note: 'DayOfWeek' might already represent this information, so this step may be redundant or used for cross-checking.\n",
    "df['DayOfWeek'] = df['Date'].dt.dayofweek  # Overwriting the existing 'DayOfWeek' if you prefer datetime's version\n",
    "df['WeekOfYear'] = df['Date'].dt.isocalendar().week\n",
    "df['IsMonthEnd'] = df['Date'].dt.is_month_end.astype(int)  # Convert boolean to int (True to 1, False to 0)\n",
    "\n",
    "# Now drop the original 'Date' column as it's no longer needed\n",
    "df.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess categorical variables using one-hot encoding\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "df = pd.get_dummies(df, columns=categorical_columns)\n",
    "\n",
    "# Handle missing values (if any)\n",
    "df.fillna(0, inplace=True)  # Filling missing values with 0, assuming it's appropriate for your dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = df.drop(columns=['Sales'])  # Features\n",
    "y = df['Sales']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Log the Model with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Step 2: Split the dataset into features and target variable\n",
    "X = df.drop(columns=['Sales'])  # Features\n",
    "y = df['Sales']  # Target variable\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Initialize MLflow experiment\n",
    "mlflow.set_experiment(\"Sales_Prediction\")\n",
    "\n",
    "# Step 5: Start MLflow run and train the model\n",
    "with mlflow.start_run() as run:\n",
    "    # Step 6: Train Linear Regression model\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Step 7: Make predictions on the test set\n",
    "    lr_predictions = lr_model.predict(X_test)\n",
    "    \n",
    "    # Step 8: Calculate Mean Squared Error\n",
    "    lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "    \n",
    "    # Step 9: Log parameters and metrics\n",
    "    mlflow.log_param(\"model_type\", \"LinearRegression\")\n",
    "    mlflow.log_metric(\"mse\", lr_mse)\n",
    "    \n",
    "    # Step 10: Log the trained model\n",
    "    mlflow.sklearn.log_model(lr_model, \"linear_regression_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Step 11: Save the trained model using pickle\n",
    "with open(\"linear_regression_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lr_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved Linear Regression model from the pickle file\n",
    "with open(\"linear_regression_model.pkl\", \"rb\") as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Example: Evaluate model performance (calculate MSE on test data)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Log the MSE metric to MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "# Example: Create a residual plot\n",
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.savefig(\"residual_plot.png\")  # Save the plot\n",
    "plt.close()\n",
    "\n",
    "# Log the residual plot to MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_artifact(\"residual_plot.png\", artifact_path=\"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "Feature 1: -0.1487664090047732\n",
      "Feature 2: -73.54862113173964\n",
      "Feature 3: 6.039733800034938\n",
      "Feature 4: 1559.0431228175187\n",
      "Feature 5: 1270.7123395748326\n",
      "Feature 6: 40.24143590910237\n",
      "Feature 7: -371.2841902528772\n",
      "Feature 8: 144.32410082117923\n",
      "Feature 9: 26.23003640182253\n",
      "Feature 10: -3.0744573806309607\n",
      "Feature 11: 2.4922607878738856\n",
      "Feature 12: 657.4678816518906\n"
     ]
    }
   ],
   "source": [
    "# Example: For Linear Regression, coefficients represent feature importance\n",
    "feature_importance = loaded_model.coef_\n",
    "print(\"Feature Importance:\")\n",
    "for i, coef in enumerate(feature_importance):\n",
    "    print(f\"Feature {i+1}: {coef}\")\n",
    "    mlflow.log_param(f\"feature_{i+1}_importance\", coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Process:\n",
      "model_type: Linear Regression\n",
      "preprocessing_steps: No preprocessing was applied\n",
      "evaluation_metric: Mean Squared Error (MSE)\n"
     ]
    }
   ],
   "source": [
    "# This could involve documenting details such as data preprocessing steps, model architecture, and evaluation metrics\n",
    "model_details = {\n",
    "    \"model_type\": \"Linear Regression\",\n",
    "    \"preprocessing_steps\": \"No preprocessing was applied\",\n",
    "    \"evaluation_metric\": \"Mean Squared Error (MSE)\"\n",
    "}\n",
    "print(\"Model Training Process:\")\n",
    "for key, value in model_details.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Visualize predicted values against actual values\n",
    "plt.scatter(y_test, loaded_model.predict(X_test))\n",
    "plt.xlabel('Actual Sales')\n",
    "plt.ylabel('Predicted Sales')\n",
    "plt.title('Actual vs. Predicted Sales')\n",
    "plt.savefig(\"actual_vs_predicted_sales.png\")  # Save the plot\n",
    "plt.close()\n",
    "\n",
    "# Log the plot as an artifact with MLflow\n",
    "mlflow.end_run()  # End the current run, if any\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_artifact(\"actual_vs_predicted_sales.png\", artifact_path=\"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error: -3.2156983109334987\n",
      "Maximum Error: 29110.67601235211\n",
      "Minimum Error: -20213.717539532692\n"
     ]
    }
   ],
   "source": [
    "# Calculate errors\n",
    "errors = y_test - loaded_model.predict(X_test)\n",
    "mean_error = errors.mean()\n",
    "max_error = errors.max()\n",
    "min_error = errors.min()\n",
    "\n",
    "# Log errors with MLflow\n",
    "mlflow.end_run()  # End the current run, if any\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metric(\"mean_error\", mean_error)\n",
    "    mlflow.log_metric(\"max_error\", max_error)\n",
    "    mlflow.log_metric(\"min_error\", min_error)\n",
    "\n",
    "# Print errors\n",
    "print(\"Mean Error:\", mean_error)\n",
    "print(\"Maximum Error:\", max_error)\n",
    "print(\"Minimum Error:\", min_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('mlflow_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment results are being tracked using MLflow or other experiment tracking tools.\n"
     ]
    }
   ],
   "source": [
    "# For demonstration purposes, we'll print a message indicating that experiment tracking is being used\n",
    "print(\"\\nExperiment results are being tracked using MLflow or other experiment tracking tools.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "logged_model = 'runs:/c0a9015fafbd4bd0b13225dc6934e68f/linear_regression_model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   44.35557092  7206.68169121  8522.92285209 ...  4091.1560226\n",
      "    21.06142582 13117.4206305 ]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the loaded model\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "# Print the predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1472.0885628746835"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_distutils_hack\\__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_distutils_hack\\__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model\", \"linear_regression\")\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "\n",
    "    # Log evaluation metrics\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"mae\", mean_absolute_error(y_test, predictions))  # Calculate MAE inline\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Visualize predicted vs actual sales and log as an artifact\n",
    "    plt.scatter(y_test, predictions)\n",
    "    plt.xlabel('Actual Sales')\n",
    "    plt.ylabel('Predicted Sales')\n",
    "    plt.title('Actual vs. Predicted Sales')\n",
    "    plt.savefig(\"actual_vs_predicted_sales.png\")  # Save the plot as an artifact\n",
    "    plt.close()  # Close the plot to prevent it from being displayed in the notebook\n",
    "    mlflow.log_artifact(\"actual_vs_predicted_sales.png\", artifact_path=\"plots\")\n",
    "\n",
    "    # Visualize residuals and log as an artifact\n",
    "    plt.scatter(predictions, residuals)\n",
    "    plt.axhline(y=0, color='r', linestyle='-')\n",
    "    plt.xlabel('Predicted Sales')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residual Plot')\n",
    "    plt.savefig(\"residual_plot.png\")  # Save the plot as an artifact\n",
    "    plt.close()  # Close the plot to prevent it from being displayed in the notebook\n",
    "    mlflow.log_artifact(\"residual_plot.png\", artifact_path=\"plots\")\n",
    "\n",
    "    # Identify outliers and log the count\n",
    "    outlier_threshold = 3 * np.std(residuals)\n",
    "    outliers = np.abs(residuals) > outlier_threshold\n",
    "    num_outliers = np.sum(outliers)\n",
    "    mlflow.log_metric(\"num_outliers\", num_outliers)\n",
    "\n",
    "    # Log the model itself\n",
    "    mlflow.sklearn.log_model(loaded_model, \"model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
